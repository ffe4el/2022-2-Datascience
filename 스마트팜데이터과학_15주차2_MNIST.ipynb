{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: If you are running this in [a colab notebook](https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb), we recommend you enable a free GPU by going:\n",
    "\n",
    "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\n",
    "\n",
    "If you are running in colab, you should install the dependencies and download the dataset by running the following cell:"
   ],
   "metadata": {
    "id": "KMndMPkQaAFV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1RG0oNgSZ0EG",
    "outputId": "c7fea54c-18ef-4421-f605-cb729b0c2c9c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\r\n",
      "  Downloading skorch-0.12.1-py3-none-any.whl (193 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m193.7/193.7 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.1.0 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from skorch) (1.9.1)\r\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from skorch) (4.64.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from skorch) (1.0.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from skorch) (1.21.5)\r\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from skorch) (0.8.10)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.0->skorch) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.0->skorch) (2.2.0)\r\n",
      "Installing collected packages: skorch\r\n",
      "Successfully installed skorch-0.12.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "KQJFzR_HaDeR"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False, cache=False)"
   ],
   "metadata": {
    "id": "ILpBOtHAaYf-"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist.data.shape"
   ],
   "metadata": {
    "id": "J_d5qqnyaZ3e",
    "outputId": "e9a74821-0cff-4a84-b422-adebb460a5c8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(70000, 784)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
    "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
   ],
   "metadata": {
    "id": "WRagbDtracNQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int64')"
   ],
   "metadata": {
    "id": "S2vas3MradZS"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
   ],
   "metadata": {
    "id": "gDo4IkNJagPG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X /= 255.0"
   ],
   "metadata": {
    "id": "6crscEPlah9M"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X.min(), X.max()"
   ],
   "metadata": {
    "id": "3NalyDR2ajZW",
    "outputId": "fd5c9ec1-2a97-412e-a715-5b44e2d9d166",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0, 1.0)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "id": "sWejds4IanLt"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert(X_train.shape[0] + X_test.shape[0] == mnist.data.shape[0])"
   ],
   "metadata": {
    "id": "F2V7Yx7zaoyF"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.shape, y_train.shape"
   ],
   "metadata": {
    "id": "qN-F8x5MaqLS"
   },
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "((52500, 784), (52500,))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Print a selection of training images and their labels"
   ],
   "metadata": {
    "id": "UyGDWyHgar6h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_example(X, y):\n",
    "    \"\"\"Plot the first 5 images and their labels in a row.\"\"\"\n",
    "    for i, (img, y) in enumerate(zip(X[:5].reshape(5, 28, 28), y[:5])):\n",
    "        plt.subplot(151 + i)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(y)"
   ],
   "metadata": {
    "id": "ysylu1C1auz9"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_example(X_train, y_train)"
   ],
   "metadata": {
    "id": "fu7i3xL9av6L"
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 5 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Neural Network with PyTorch\n",
    "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
   ],
   "metadata": {
    "id": "KR0k4inxaxoD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m137.9/137.9 MB\u001B[0m \u001B[31m20.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.3.0)\r\n",
      "Installing collected packages: torch\r\n",
      "Successfully installed torch-1.13.0\r\n",
      "Requirement already satisfied: torch in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (1.13.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/sola/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "id": "dxCBxX9ya0Up"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "id": "-SeKsW9Va1qN"
   },
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_dim = X.shape[1]\n",
    "hidden_dim = int(mnist_dim/8)\n",
    "output_dim = len(np.unique(mnist.target))"
   ],
   "metadata": {
    "id": "lRchmLwLa2q5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_dim, hidden_dim, output_dim"
   ],
   "metadata": {
    "id": "72LJXw-Ma4BA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A Neural network in PyTorch's framework."
   ],
   "metadata": {
    "id": "FQJxnmxCa54n"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=mnist_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=output_dim,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = F.relu(self.hidden(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ],
   "metadata": {
    "id": "vQru86L5a7Kt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "skorch allows to use PyTorch's networks in the SciKit-Learn setting:"
   ],
   "metadata": {
    "id": "XTOVHe_7a-s7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from skorch import NeuralNetClassifier"
   ],
   "metadata": {
    "id": "KdyEDD-ebABp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "id": "mlGANjv4bBqs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "net.fit(X_train, y_train);"
   ],
   "metadata": {
    "id": "2UbnkQUGbDkw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {
    "id": "kX-eqPvSbFNM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "id": "mPWGK7VqbHoo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = net.predict(X_test)"
   ],
   "metadata": {
    "id": "zAYM6ojcbIsM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "id": "GHsuVeNobKEo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "An accuracy of about 96% for a network with only one hidden layer is not too bad.\n",
    "\n",
    "Let's take a look at some predictions that went wrong:"
   ],
   "metadata": {
    "id": "LTkY1jr4bMQw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "error_mask = y_pred != y_test"
   ],
   "metadata": {
    "id": "vcRm6zCNbNiX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_example(X_test[error_mask], y_pred[error_mask])"
   ],
   "metadata": {
    "id": "f5JLNrEvbPAg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Network\n",
    "PyTorch expects a 4 dimensional tensor as input for its 2D convolution layer. The dimensions represent:\n",
    "* Batch size\n",
    "* Number of channel\n",
    "* Height\n",
    "* Width\n",
    "\n",
    "As initial batch size the number of examples needs to be provided. MNIST data has only one channel. As stated above, each MNIST vector represents a 28x28 pixel image. Hence, the resulting shape for PyTorch tensor needs to be (x, 1, 28, 28). "
   ],
   "metadata": {
    "id": "YHYFQfyNbQOC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "XCnn = X.reshape(-1, 1, 28, 28)"
   ],
   "metadata": {
    "id": "jFybYhWhbR9G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "XCnn.shape"
   ],
   "metadata": {
    "id": "ySTYLtyqbUOA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "XCnn_train, XCnn_test, y_train, y_test = train_test_split(XCnn, y, test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "id": "HQLi_qPQbVn-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "XCnn_train.shape, y_train.shape"
   ],
   "metadata": {
    "id": "WxrceUyNbXLc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
    "        self.fc1 = nn.Linear(1600, 100) # 1600 = number channels * width * height\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc1_drop = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        \n",
    "        # flatten over channel, height and width = 1600\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
    "        \n",
    "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
    "        x = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return x"
   ],
   "metadata": {
    "id": "C0yC_CEhbYTu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "cnn = NeuralNetClassifier(\n",
    "    CNN,\n",
    "    max_epochs=10,\n",
    "    lr=0.002,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    device=device,\n",
    ")"
   ],
   "metadata": {
    "id": "-C5BnX8qbbRa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cnn.fit(XCnn_train, y_train);"
   ],
   "metadata": {
    "id": "HNMdzTzCbfN7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred_cnn = cnn.predict(XCnn_test)"
   ],
   "metadata": {
    "id": "NKQ1Q5GZbgoL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy_score(y_test, y_pred_cnn)"
   ],
   "metadata": {
    "id": "r2UqopsEbhpV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "An accuracy of >98% should suffice for this example!\n",
    "\n",
    "Let's see how we fare on the examples that went wrong before:"
   ],
   "metadata": {
    "id": "BuR2KiFNbnUF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy_score(y_test[error_mask], y_pred_cnn[error_mask])"
   ],
   "metadata": {
    "id": "hq3UJ0-pbi5K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Over 70% of the previously misclassified images are now correctly identified."
   ],
   "metadata": {
    "id": "_dogvjIcbp-l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot_example(X_test[error_mask], y_pred_cnn[error_mask])"
   ],
   "metadata": {
    "id": "I2JjxN9abkuK"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
